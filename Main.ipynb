import zipfile, os, random
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt
import ipywidgets as widgets
from IPython.display import display

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models

# --- Step 1: Unzip dataset ---
zip_path = "/content/drive/MyDrive/DATASET.zip"
extract_path = "/content/drive/MyDrive/DATASET"
if not os.path.exists(extract_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall("/content/drive/MyDrive")
    print("✅ Dataset extracted.")
else:
    print("✅ Dataset already extracted.")

# --- Step 2: Dataset paths ---
left_dir = "/content/drive/MyDrive/DATASET/left/left"
right_dir = "/content/drive/MyDrive/DATASET/right/right"

# --- Step 3: Dataset Class ---
class StereoPairDataset(Dataset):
    def __init__(self, left_dir, right_dir, transform=None):
        self.left_images = sorted(os.listdir(left_dir))
        self.right_images = sorted(os.listdir(right_dir))
        self.left_dir = left_dir
        self.right_dir = right_dir
        self.transform = transform

    def __len__(self):
        return len(self.left_images)

    def __getitem__(self, idx):
        left_path = os.path.join(self.left_dir, self.left_images[idx])
        left_img = Image.open(left_path).convert('RGB')

        if random.random() > 0.5:
            # ASYNC case: mismatched pair
            other_idx = random.choice([i for i in range(len(self.right_images)) if i != idx])
            right_path = os.path.join(self.right_dir, self.right_images[other_idx])
            label = 0  # async
        else:
            # SYNC case: matched pair
            right_path = os.path.join(self.right_dir, self.right_images[idx])
            label = 1  # sync

        right_img = Image.open(right_path).convert('RGB')

        if self.transform:
            left_img = self.transform(left_img)
            right_img = self.transform(right_img)

        return left_img, right_img, torch.tensor(label, dtype=torch.float32)

# --- Step 4: Transforms ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# --- Step 5: DataLoader ---
dataset = StereoPairDataset(left_dir, right_dir, transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)

# --- Step 6: Model Definition ---
class StereoSyncNet(nn.Module):
    def __init__(self):
        super(StereoSyncNet, self).__init__()
        resnet = models.resnet18(pretrained=True)
        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])
        self.classifier = nn.Sequential(
            nn.Linear(512 * 2, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, left_img, right_img):
        left_feat = self.feature_extractor(left_img).view(left_img.size(0), -1)
        right_feat = self.feature_extractor(right_img).view(right_img.size(0), -1)
        combined = torch.cat((left_feat, right_feat), dim=1)
        return self.classifier(combined).squeeze()

# --- Step 7: Training ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = StereoSyncNet().to(device)
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

num_epochs = 20
for epoch in range(num_epochs):
    model.train()
    running_loss, correct, total = 0, 0, 0
    for left_img, right_img, labels in dataloader:
        left_img, right_img, labels = left_img.to(device), right_img.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(left_img, right_img)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * labels.size(0)
        preds = (outputs > 0.5).float()
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    print(f"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/total:.4f} - Acc: {correct/total:.4f}")

# --- Step 8: Save Model ---
model_path = "/content/drive/MyDrive/stereo_sync_model_fixed.pth"
torch.save(model.state_dict(), model_path)
print("✅ Model saved to:", model_path)

# --- Step 9: Load for Evaluation ---
model_eval = StereoSyncNet().to(device)
model_eval.load_state_dict(torch.load(model_path, map_location=device))
model_eval.eval()

# --- Step 10: UI for Upload & Compare ---
def get_uploaded_image(file_upload):
    if len(file_upload.value) == 0:
        return None
    key = list(file_upload.value.keys())[0]
    content = file_upload.value[key]['content']
    return Image.open(BytesIO(content)).convert('RGB')

def show_images_side_by_side(img1, img2, title1="Left", title2="Right"):
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))
    axes[0].imshow(img1)
    axes[0].set_title(title1)
    axes[0].axis('off')
    axes[1].imshow(img2)
    axes[1].set_title(title2)
    axes[1].axis('off')
    plt.show()

def run_sync_async_check():
    print("Upload LEFT image:")
    upload_left = widgets.FileUpload(accept='image/*', multiple=False)
    display(upload_left)

    print("Upload RIGHT image:")
    upload_right = widgets.FileUpload(accept='image/*', multiple=False)
    display(upload_right)

    def on_button_click(b):
        left_img = get_uploaded_image(upload_left)
        right_img = get_uploaded_image(upload_right)

        if left_img is None or right_img is None:
            print("⚠️ Please upload both images!")
            return

        show_images_side_by_side(left_img, right_img)

        left_tensor = transform(left_img).unsqueeze(0).to(device)
        right_tensor = transform(right_img).unsqueeze(0).to(device)

        with torch.no_grad():
            prob = model_eval(left_tensor, right_tensor).item()

        print(f"Model Prediction: {prob:.4f} → {'Sync' if prob > 0.5 else 'Async'}")

    btn = widgets.Button(description="Check Sync/Async")
    btn.on_click(on_button_click)
    display(btn)

# --- Step 11: Run UI ---
run_sync_async_check()
